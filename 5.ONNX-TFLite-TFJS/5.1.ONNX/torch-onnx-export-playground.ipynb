{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pytorch Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_lightning import LightningModule\n",
    "\n",
    "\n",
    "class SimpleModel(LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = torch.nn.Linear(in_features=64, out_features=4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.relu(self.l1(x.view(x.size(0), -1)))\n",
    "\n",
    "\n",
    "model = SimpleModel()\n",
    "filepath = \"exports/test_pytorch_lightning.onnx\"\n",
    "input_sample = torch.randn((1, 64))\n",
    "model.to_onnx(filepath, input_sample, export_params=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pytorch + Pytorch Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer2(x)\n",
    "        if x.max() > 0.5:\n",
    "            return x ** 2\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightningModel(pl.LightningModule):\n",
    "    def __init__(self, input_size, hidden_size, output_size, learning_rate=1e-3):\n",
    "        super(LightningModel, self).__init__()\n",
    "        # Use the PyTorch model as self.model\n",
    "        self.model = SimpleModel(input_size, hidden_size, output_size)\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "        self.log(\"val_loss\", loss)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LightningModel(input_size=10, hidden_size=32, output_size=1)\n",
    "filepath = \"exports/test_pytorch_lightning_2.onnx\"\n",
    "input_sample = torch.randn((1, 10))\n",
    "model.to_onnx(filepath, input_sample, export_params=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two submodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.onnx\n",
    "\n",
    "\n",
    "class SubModelA(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SubModelA, self).__init__()\n",
    "        self.fc = nn.Linear(10, 5)\n",
    "\n",
    "    def score(self, x):\n",
    "        return torch.relu(self.fc(x))\n",
    "\n",
    "\n",
    "class SubModelB(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SubModelB, self).__init__()\n",
    "        self.fc = nn.Linear(5, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.softmax(self.fc(x), dim=1)\n",
    "\n",
    "\n",
    "class MainModel(nn.Module):\n",
    "    def __init__(self, model_a, model_b):\n",
    "        super(MainModel, self).__init__()\n",
    "        self.models = nn.ModuleDict({\n",
    "            \"model_a\": model_a,\n",
    "            \"model_b\": model_b\n",
    "        })\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass input through SubModelA, then SubModelB\n",
    "        x = self.models[\"model_a\"].score(x)\n",
    "        x = self.models[\"model_b\"](x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Instantiate and test the model\n",
    "model_a = SubModelA()\n",
    "model_b = SubModelB()\n",
    "model = MainModel(model_a, model_b)\n",
    "sample_input = torch.randn(1, 10)\n",
    "output = model(sample_input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"exports/test_pytorch_2_sub_model.onnx\"\n",
    "model.eval()  # Set model to evaluation mode\n",
    "dummy_input = torch.randn(1, 10)  # Input shape must match the model's input\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    filepath,\n",
    "    export_params=True,\n",
    "    input_names=[\"input\"],\n",
    "    output_names=[\"output\"],\n",
    "    dynamic_axes={\"input\": {0: \"batch_size\"}, \"output\": {0: \"batch_size\"}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "\n",
    "filepath = \"exports/test_pytorch_2_sub_model.onnx\"\n",
    "# Load the ONNX model\n",
    "session = ort.InferenceSession(filepath)\n",
    "\n",
    "# Create a sample input matching the ONNX model input shape\n",
    "dummy_input = np.random.randn(1, 10).astype(np.float32)\n",
    "\n",
    "# Run inference\n",
    "outputs = session.run(None, {\"input\": dummy_input})\n",
    "print(\"ONNX Model Output:\", outputs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dynamo export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class MLPModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc0 = nn.Linear(8, 8, bias=True)\n",
    "        self.fc1 = nn.Linear(8, 4, bias=True)\n",
    "        self.fc2 = nn.Linear(4, 2, bias=True)\n",
    "        self.fc3 = nn.Linear(2, 2, bias=True)\n",
    "\n",
    "    def forward(self, tensor_x: torch.Tensor):\n",
    "        tensor_x = self.fc0(tensor_x)\n",
    "        tensor_x = torch.sigmoid(tensor_x)\n",
    "        tensor_x = self.fc1(tensor_x)\n",
    "        tensor_x = torch.sigmoid(tensor_x)\n",
    "        tensor_x = self.fc2(tensor_x)\n",
    "        tensor_x = torch.sigmoid(tensor_x)\n",
    "        output = self.fc3(tensor_x)\n",
    "        return output\n",
    "\n",
    "\n",
    "model = MLPModel()\n",
    "tensor_x = torch.rand((97, 8), dtype=torch.float32)\n",
    "export_options = torch.onnx.ExportOptions(dynamic_shapes=True)\n",
    "onnx_program = torch.onnx.dynamo_export(model, tensor_x, export_options=export_options)\n",
    "onnx_program.save(\"exports/test_pytorch_dynamo.onnx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
